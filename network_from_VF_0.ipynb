{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import Geod\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import graph_tool.all as gt\n",
    "import networkx as nx\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data frame into memory\n",
    "df = pd.read_csv('./VF_data/pandemos_tra_tapas_modell.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort data by person and by start time\n",
    "df = df.sort_values(['p_id', 'start_time_min'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nnodes(df, n):\n",
    "    # Returns a list of n lists where each list contains all indices in the df of a certain node\n",
    "    # The n selected nodes are choosen in order of appearence in df\n",
    "    # Expects the df to be sorted by p_id and start_time_min\n",
    "\n",
    "    unique_nodes = df.p_id.unique()\n",
    "    nnodes = []\n",
    "    \n",
    "    if not n:\n",
    "        n = len(unique_nnodes) # select all nodes if n is not provided\n",
    "\n",
    "    elif len(unique_nodes) < n: # select at maximum all available nodes in df\n",
    "        n = len(unique_nodes)\n",
    "\n",
    "    print(n)\n",
    "\n",
    "    last_ind, first_ind = 0, 0\n",
    "    for node in tqdm(unique_nodes[:n], total=n):\n",
    "        while True:\n",
    "            if df.iloc[first_ind].p_id != node:\n",
    "                nnodes.append(list(range(last_ind, first_ind)))\n",
    "                break\n",
    "\n",
    "            first_ind += 1\n",
    "        \n",
    "        last_ind = first_ind\n",
    "        \n",
    "    \n",
    "    return nnodes, unique_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position_vector_nnodes2(df, n):\n",
    "    # create points in space and time for every node\n",
    "    index, unique_nnodes = get_nnodes(df, n)\n",
    "    geod = Geod(\"+ellps=WGS84\")\n",
    "\n",
    "    # get edges of time interval\n",
    "    index_flat = [item for sublist in index for item in sublist]\n",
    "    tmin = df.iloc[index_flat].start_time_min.min()\n",
    "\n",
    "    if tmin < 0:\n",
    "        tmin = abs(tmin)\n",
    "    else:\n",
    "        tmin = 0\n",
    "    tmax = (df.iloc[index_flat].activity_start_min + df.iloc[index_flat].activity_duration_min).max() + tmin\n",
    "\n",
    "    R_lons2, R_lats2 = [], []\n",
    "    R_lons, R_lats = [], []\n",
    "\n",
    "    for i, (ind, id) in tqdm(enumerate(zip(index, unique_nnodes)), total=n):\n",
    "        # get all df entries of current node\n",
    "        dfj = df.iloc[ind]\n",
    "\n",
    "        # convert trajectories and activites into position vector R(t)=((lon_0, lat_1), (lon_1, lat_1), ..., (lon_max, lat_max))^T\n",
    "        S_loni, S_lati = dfj.lon_start.to_numpy(), dfj.lat_start.to_numpy()\n",
    "        F_loni, F_lati = dfj.lon_end.to_numpy(), dfj.lat_end.to_numpy()\n",
    "        T = (dfj.travel_time_sec / 60).round(0).to_numpy(int)\n",
    "        At = dfj.activity_duration_min.to_numpy()\n",
    "        wait = dfj.start_time_min.iloc[0] + tmin\n",
    "\n",
    "        R = [(np.nan, np.nan),]*wait\n",
    "        for lon1, lat1, lon2, lat2, npts, Ati in zip(S_loni, S_lati, F_loni, F_lati, T, At):\n",
    "            Gi = geod.npts(lon1, lat1, lon2, lat2, npts, initial_idx=0, terminus_idx=0) # get points on geodesic\n",
    "            Ai = [(lon2, lat2),]*Ati\n",
    "            R += Gi + Ai\n",
    "\n",
    "        R += [(np.nan, np.nan),]*(tmax - len(R))\n",
    "        R = list(map(list, zip(*R))) # fast python list transpose\n",
    "        \n",
    "        R_lons.append(R[0])\n",
    "        R_lats.append(R[1])\n",
    "\n",
    "    # due to precission issues it is possible that the node with smallest overall starting time\n",
    "    # has a slightly larger amount of entries. Handle this in the following exception by ignoring\n",
    "    # first n time steps        \n",
    "    try:\n",
    "        R_lons = np.array(R_lons)\n",
    "        R_lats = np.array(R_lats)\n",
    "    except ValueError:\n",
    "        print('Over shoot due to precission error')\n",
    "        length = len(R_lons[0])\n",
    "        for i, R in enumerate(R_lons):\n",
    "            if len(R) != length:\n",
    "                over_shoot = len(R) - length\n",
    "                R_lons[i] = R_lons[i][over_shoot: ]\n",
    "                R_lats[i] = R_lats[i][over_shoot: ]\n",
    "                \n",
    "                R_lons = np.array(R_lons)\n",
    "                R_lats = np.array(R_lats)\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "    # Return in format R_x(t)=[[r1(t=0), r2(t=0), ..., rn(t=0)], [r1(t=1), r2(t=1), ..., rn(t=tmax)], ..., [r1(t=tmax), r2(t=tmax), ..., rn(t=tmax)]]\n",
    "    return R_lons.T, R_lats.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['activity_end_min'] = df['activity_start_min'] + df['activity_duration_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = []\n",
    "\n",
    "def get_contacts(grp):\n",
    "    print(grp)\n",
    "    print(grp['activity_end_min'].apply(lambda end: grp['activity_start_min'] < end))\n",
    "    print('\\n\\n\\n')\n",
    "    \n",
    "\n",
    "df.groupby('loc_id_end')[['p_id', 'activity_start_min', 'activity_end_min']].apply(get_contacts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandemic_networks_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
